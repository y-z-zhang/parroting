{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.utils import vpt_smape, vpt_nrmse, vpt_mse, smape_rolling\n",
    "from scipy.spatial.distance import cdist\n",
    "from dysts.systems import get_attractor_list\n",
    "from dysts.flows import __dict__ as flow_models\n",
    "from dysts.analysis import gp_dim\n",
    "from dysts.metrics import estimate_kl_divergence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a delay embedding\n",
    "def delay_embedding(data, D=30, tau=1):\n",
    "    \"\"\"\n",
    "    Create a delay embedding of a time series\n",
    "\n",
    "    Args:\n",
    "        data: 1D array representing the context trajectory\n",
    "        D: embedding dimension\n",
    "        tau: delay used for the embedding\n",
    "\n",
    "    Returns:\n",
    "        embedded_data: Delay embedded data\n",
    "\n",
    "    Usage:\n",
    "        arr = np.array([1,2,3,4,5,6,7,8,9])\n",
    "        delay_embedding(arr,5,1)\n",
    "    \"\"\"\n",
    "    N = len(data)\n",
    "    indices = np.arange(D) * tau + np.arange(N - (D - 1) * tau)[:, None]\n",
    "    embedded_data = data[indices]\n",
    "    #print(embedded_data.shape)\n",
    "    return embedded_data\n",
    "\n",
    "def embedding_distance(data, D=30, tau=1):\n",
    "    \"\"\"\n",
    "    Calculate the L2 distance in a delay-embedded space\n",
    "\n",
    "    Args:\n",
    "        data: 1D array representing the context trajectory\n",
    "        D: embedding dimension, needs to be large enough\n",
    "        tau: delay used for the embedding, probably fine to just set to 1\n",
    "\n",
    "    Returns:\n",
    "        min_l2_distance: Minimum L2 distance in the embedding space\n",
    "    \"\"\"\n",
    "\n",
    "    # Create delay embeddings\n",
    "    embedded_data = delay_embedding(data, D=D, tau=tau)\n",
    "\n",
    "    # Compute distance of other points to the last point in the embedding space using L2 norm\n",
    "    last_point = embedded_data[-1]\n",
    "    l2_distance = cdist(embedded_data[:-D * tau], last_point[None, :])\n",
    "    #l2_distance = cdist(embedded_data[:-5], last_point[None, :])\n",
    "    #print(l2_distance)\n",
    "\n",
    "    return l2_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_parroting_forecast(data, D=30, tau=1, forecast_total_length=300):\n",
    "    \"\"\"\n",
    "    Simple forecasting model based on context parroting.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): The input 1D array representing the context trajectory.\n",
    "        D (int): Context window size for comparing past data (default 30).\n",
    "        forecast_total_length (int): Desired length of the forecasted output (default 512).\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - best_index (int): Index of the best-matching context point.\n",
    "            - min_embedding_distance (float): Minimum L2 distance in the embedding space.\n",
    "            - forecast (array-like): Forecasted sequence of the specified length.\n",
    "    \"\"\"\n",
    "\n",
    "    #if D * tau >= len(data)-10:\n",
    "    #    #raise ValueError(\"D * tau is too large for the data\")\n",
    "    #    D = len(data)//2\n",
    "\n",
    "    # Calculate embedding distances\n",
    "    embedding_distances = embedding_distance(data, D=D, tau=tau)\n",
    "    min_embedding_distance = np.min(embedding_distances)\n",
    "\n",
    "    # Find the index with the minimum embedding distance\n",
    "    min_index = np.argmin(embedding_distances)\n",
    "    best_index = min_index + (D-1)*tau + 1\n",
    "\n",
    "    # Extract the motif starting from the best-matching index\n",
    "    motif = data[best_index:-1]\n",
    "    motif_length = len(motif)\n",
    "\n",
    "    # Repeat the motif to create a forecast of the desired length\n",
    "    num_repeats = forecast_total_length // motif_length + 1\n",
    "    forecast = np.tile(motif, num_repeats)[:forecast_total_length]\n",
    "\n",
    "    return best_index, min_embedding_distance, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = 30\n",
    "context_lengths = 2**np.arange(6, 17)\n",
    "forecast_length = 300\n",
    "#simulation_length = 10000\n",
    "simulation_length = 100000\n",
    "rolling_window = 64\n",
    "num_ic = 100\n",
    "D = 5\n",
    "# Directory to store trajectories\n",
    "#trajectory_dir = \"trajectories\"\n",
    "trajectory_dir = \"long_trajectories\"\n",
    "os.makedirs(trajectory_dir, exist_ok=True)\n",
    "\n",
    "equation_names = get_attractor_list()\n",
    "equation_names.remove('FluidTrampoline')\n",
    "equation_names.remove('HyperLu')\n",
    "equation_names.remove('SprottMore')\n",
    "equation_names.remove('StickSlipOscillator')\n",
    "#equation_names = equation_names[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    \n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "def mse_rolling(ts1, ts2):\n",
    "\n",
    "    n = min(ts1.shape[0], ts2.shape[0])\n",
    "    all_mse = list()\n",
    "    for i in range(1, n+1):\n",
    "        mse_val = mse(ts1[:i], ts2[:i])\n",
    "        all_mse.append(mse_val)\n",
    "\n",
    "    return np.array(all_mse)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    \n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae\n",
    "\n",
    "def mae_rolling(ts1, ts2):\n",
    "\n",
    "    n = min(ts1.shape[0], ts2.shape[0])\n",
    "    all_mae = list()\n",
    "    for i in range(1, n+1):\n",
    "        mae_val = mae(ts1[:i], ts2[:i])\n",
    "        all_mae.append(mae_val)\n",
    "\n",
    "    return np.array(all_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_vpt = dict()\n",
    "median_vpt = dict()\n",
    "average_smape = dict()\n",
    "median_smape = dict()\n",
    "\n",
    "average_vpt_2 = dict()\n",
    "median_vpt_2 = dict()\n",
    "average_smape_2 = dict()\n",
    "median_smape_2 = dict()\n",
    "\n",
    "average_l2 = dict()\n",
    "median_l2 = dict()\n",
    "\n",
    "average_cdim = dict()\n",
    "median_cdim = dict()\n",
    "average_kl = dict()\n",
    "median_kl = dict()\n",
    "\n",
    "average_mse = dict()\n",
    "median_mse = dict()\n",
    "average_mae = dict()\n",
    "median_mae = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing trajectory for Aizawa...\n",
      "Loading existing trajectory for AnishchenkoAstakhov...\n",
      "Loading existing trajectory for Arneodo...\n",
      "Loading existing trajectory for ArnoldBeltramiChildress...\n",
      "Loading existing trajectory for ArnoldWeb...\n",
      "Loading existing trajectory for AtmosphericRegime...\n",
      "Loading existing trajectory for BeerRNN...\n",
      "Loading existing trajectory for BelousovZhabotinsky...\n",
      "Loading existing trajectory for BickleyJet...\n",
      "Loading existing trajectory for Blasius...\n",
      "Loading existing trajectory for BlinkingRotlet...\n",
      "Loading existing trajectory for BlinkingVortex...\n",
      "Loading existing trajectory for Bouali...\n",
      "Loading existing trajectory for Bouali2...\n",
      "Loading existing trajectory for BurkeShaw...\n",
      "Loading existing trajectory for CaTwoPlus...\n",
      "Loading existing trajectory for CaTwoPlusQuasiperiodic...\n",
      "Loading existing trajectory for CellCycle...\n",
      "Loading existing trajectory for CellularNeuralNetwork...\n",
      "Loading existing trajectory for Chen...\n",
      "Loading existing trajectory for ChenLee...\n",
      "Loading existing trajectory for Chua...\n",
      "Loading existing trajectory for CircadianRhythm...\n",
      "Loading existing trajectory for CoevolvingPredatorPrey...\n",
      "Loading existing trajectory for Colpitts...\n",
      "Loading existing trajectory for Coullet...\n",
      "Loading existing trajectory for Dadras...\n",
      "Loading existing trajectory for DequanLi...\n",
      "Loading existing trajectory for DoubleGyre...\n",
      "Loading existing trajectory for DoublePendulum...\n",
      "Loading existing trajectory for Duffing...\n",
      "Loading existing trajectory for ExcitableCell...\n",
      "Loading existing trajectory for Finance...\n",
      "Loading existing trajectory for ForcedBrusselator...\n",
      "Loading existing trajectory for ForcedFitzHughNagumo...\n",
      "Loading existing trajectory for ForcedVanDerPol...\n",
      "Loading existing trajectory for GenesioTesi...\n",
      "Loading existing trajectory for GlycolyticOscillation...\n",
      "Loading existing trajectory for GuckenheimerHolmes...\n",
      "Loading existing trajectory for Hadley...\n",
      "Loading existing trajectory for Halvorsen...\n",
      "Loading existing trajectory for HastingsPowell...\n",
      "Loading existing trajectory for HenonHeiles...\n",
      "Loading existing trajectory for HindmarshRose...\n",
      "Loading existing trajectory for Hopfield...\n",
      "Loading existing trajectory for HyperBao...\n",
      "Loading existing trajectory for HyperCai...\n",
      "Loading existing trajectory for HyperJha...\n",
      "Loading existing trajectory for HyperLorenz...\n",
      "Loading existing trajectory for HyperPang...\n",
      "Loading existing trajectory for HyperQi...\n",
      "Loading existing trajectory for HyperRossler...\n",
      "Loading existing trajectory for HyperWang...\n",
      "Loading existing trajectory for HyperXu...\n",
      "Loading existing trajectory for HyperYan...\n",
      "Loading existing trajectory for HyperYangChen...\n",
      "Loading existing trajectory for IkedaDelay...\n",
      "Loading existing trajectory for InteriorSquirmer...\n",
      "Loading existing trajectory for IsothermalChemical...\n",
      "Loading existing trajectory for ItikBanksTumor...\n",
      "Loading existing trajectory for JerkCircuit...\n",
      "Loading existing trajectory for KawczynskiStrizhak...\n",
      "Loading existing trajectory for Laser...\n",
      "Loading existing trajectory for LidDrivenCavityFlow...\n",
      "Loading existing trajectory for LiuChen...\n",
      "Loading existing trajectory for Lorenz...\n",
      "Loading existing trajectory for Lorenz84...\n",
      "Loading existing trajectory for Lorenz96...\n",
      "Loading existing trajectory for LorenzBounded...\n",
      "Loading existing trajectory for LorenzCoupled...\n",
      "Loading existing trajectory for LorenzStenflo...\n",
      "Loading existing trajectory for LuChen...\n",
      "Loading existing trajectory for LuChenCheng...\n",
      "Loading existing trajectory for MacArthur...\n",
      "Loading existing trajectory for MackeyGlass...\n",
      "Loading existing trajectory for MooreSpiegel...\n",
      "Loading existing trajectory for MultiChua...\n",
      "Loading existing trajectory for NewtonLiepnik...\n",
      "Loading existing trajectory for NoseHoover...\n",
      "Loading existing trajectory for NuclearQuadrupole...\n",
      "Loading existing trajectory for OscillatingFlow...\n",
      "Loading existing trajectory for PanXuZhou...\n",
      "zero-size array to reduction operation minimum which has no identity\n",
      "Skipping PanXuZhou\n",
      "Loading existing trajectory for PehlivanWei...\n",
      "Loading existing trajectory for PiecewiseCircuit...\n",
      "Loading existing trajectory for Qi...\n",
      "Loading existing trajectory for QiChen...\n",
      "Loading existing trajectory for RabinovichFabrikant...\n",
      "Loading existing trajectory for RayleighBenard...\n",
      "Loading existing trajectory for RikitakeDynamo...\n",
      "Loading existing trajectory for Rossler...\n",
      "Loading existing trajectory for Rucklidge...\n",
      "Loading existing trajectory for Sakarya...\n",
      "Loading existing trajectory for SaltonSea...\n",
      "Loading existing trajectory for SanUmSrisuchinwong...\n",
      "Loading existing trajectory for ScrollDelay...\n",
      "Loading existing trajectory for ShimizuMorioka...\n",
      "Loading existing trajectory for SprottA...\n",
      "Loading existing trajectory for SprottB...\n",
      "Loading existing trajectory for SprottC...\n",
      "Loading existing trajectory for SprottD...\n",
      "Loading existing trajectory for SprottDelay...\n",
      "Loading existing trajectory for SprottE...\n",
      "Loading existing trajectory for SprottF...\n",
      "Loading existing trajectory for SprottG...\n",
      "Loading existing trajectory for SprottH...\n",
      "Loading existing trajectory for SprottI...\n",
      "Loading existing trajectory for SprottJ...\n",
      "Loading existing trajectory for SprottJerk...\n",
      "Loading existing trajectory for SprottK...\n",
      "Loading existing trajectory for SprottL...\n",
      "Loading existing trajectory for SprottM...\n",
      "Loading existing trajectory for SprottN...\n",
      "Loading existing trajectory for SprottO...\n",
      "Loading existing trajectory for SprottP...\n",
      "Loading existing trajectory for SprottQ...\n",
      "Loading existing trajectory for SprottR...\n",
      "Loading existing trajectory for SprottS...\n",
      "Loading existing trajectory for SprottTorus...\n",
      "Loading existing trajectory for SwingingAtwood...\n",
      "Loading existing trajectory for Thomas...\n",
      "Loading existing trajectory for ThomasLabyrinth...\n",
      "Loading existing trajectory for Torus...\n",
      "Loading existing trajectory for Tsucs2...\n",
      "Loading existing trajectory for TurchinHanski...\n",
      "Loading existing trajectory for VallisElNino...\n",
      "Loading existing trajectory for VossDelay...\n",
      "Loading existing trajectory for WangSun...\n",
      "Loading existing trajectory for WindmiReduced...\n",
      "Loading existing trajectory for YuWang...\n",
      "Loading existing trajectory for YuWang2...\n",
      "Loading existing trajectory for ZhouChen...\n"
     ]
    }
   ],
   "source": [
    "for equation_name in equation_names:\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Path to the trajectory file\n",
    "        trajectory_path = os.path.join(trajectory_dir, f\"{equation_name}.npy\")\n",
    "\n",
    "        # Check if the trajectory file already exists\n",
    "        if os.path.exists(trajectory_path):\n",
    "            print(f\"Loading existing trajectory for {equation_name}...\")\n",
    "            traj = np.load(trajectory_path)\n",
    "        else:\n",
    "            # Generate the trajectory\n",
    "            print(f\"Generating trajectory for {equation_name}...\")\n",
    "            model_class = flow_models[equation_name]  # Get the model class dynamically\n",
    "            model = model_class()  # Instantiate the model\n",
    "            traj = model.make_trajectory(simulation_length, pts_per_period=granularity)\n",
    "\n",
    "            # Save the trajectory\n",
    "            np.save(trajectory_path, traj)\n",
    "            print(f\"Saved trajectory for {equation_name} at {trajectory_path}\")\n",
    "\n",
    "        # normalize the trajectory\n",
    "        traj = (traj - np.mean(traj, axis=0)) / np.std(traj, axis=0)\n",
    "\n",
    "        for context_length in context_lengths:\n",
    "\n",
    "            all_vpt = list() # collecting all vpt for the parroting model\n",
    "            all_smape_rolling = list() # collecting all smape values across time\n",
    "            all_vpt_2 = list() # collecting all vpt for the parroting model\n",
    "            all_smape_rolling_2 = list() # collecting all smape values across time\n",
    "            all_l2 = list() # collecting all l2 distances for the embedding model\n",
    "            all_cdim = list() # collecting all correlation dimensions\n",
    "            all_kl_dist = list() # collecting all kl divergence values\n",
    "            all_mse_rolling = list()\n",
    "            all_mae_rolling = list()\n",
    "\n",
    "            for i in range(0, len(traj)-context_length-forecast_length, rolling_window):\n",
    "                if i < rolling_window*num_ic:\n",
    "                    #print(i//rolling_window)\n",
    "                    traj_context = traj[i:i+context_length,:]\n",
    "                    traj_true = traj[i+context_length:i+context_length+forecast_length,:]\n",
    "                    traj_pred_full = np.zeros_like(traj_true)\n",
    "\n",
    "                    for dim in range(traj_true.shape[1]):\n",
    "\n",
    "                        best_index, min_l2_distance, traj_pred = context_parroting_forecast(traj_context[:,dim], D=D)\n",
    "                        traj_pred_full[:,dim] = traj_pred\n",
    "\n",
    "                        vpt = vpt_smape(traj_pred, traj_true[:,dim]) / granularity\n",
    "                        smape_val = np.array(smape_rolling(traj_true[:, dim], traj_pred))\n",
    "\n",
    "                        all_vpt.append(vpt)\n",
    "                        all_smape_rolling.append(smape_val)\n",
    "\n",
    "                        all_l2.append(min_l2_distance)\n",
    "\n",
    "                        mse_val = mse_rolling(traj_true[:, dim], traj_pred)\n",
    "                        all_mse_rolling.append(mse_val)\n",
    "                        \n",
    "                        mae_val = mae_rolling(traj_true[:, dim], traj_pred)\n",
    "                        all_mae_rolling.append(mae_val)\n",
    "\n",
    "                    vpt = vpt_smape(traj_pred_full.squeeze(), traj_true.squeeze()) / granularity\n",
    "                    smape_val = np.array(smape_rolling(traj_true, traj_pred_full))\n",
    "                    all_vpt_2.append(vpt)\n",
    "                    all_smape_rolling_2.append(smape_val)\n",
    "                    \n",
    "                    kl_dist = estimate_kl_divergence(traj_true, traj_pred_full)\n",
    "                    if np.isinf(kl_dist):\n",
    "                        kl_dist = np.nan\n",
    "                    all_kl_dist.append(kl_dist)\n",
    "\n",
    "                    cdim_pred = gp_dim(traj_pred_full)\n",
    "                    cdim_true = gp_dim(traj_true)\n",
    "                    all_cdim.append(np.array([cdim_pred, cdim_true]))\n",
    "\n",
    "            average_vpt[(equation_name,context_length)] = np.mean(all_vpt)\n",
    "            median_vpt[(equation_name,context_length)] = np.median(all_vpt)\n",
    "            average_smape[(equation_name,context_length)] = np.mean(all_smape_rolling, axis=0)\n",
    "            median_smape[(equation_name,context_length)] = np.median(all_smape_rolling, axis=0)\n",
    "\n",
    "            average_vpt_2[(equation_name,context_length)] = np.mean(all_vpt_2)\n",
    "            median_vpt_2[(equation_name,context_length)] = np.median(all_vpt_2)\n",
    "            average_smape_2[(equation_name,context_length)] = np.mean(all_smape_rolling_2, axis=0)\n",
    "            median_smape_2[(equation_name,context_length)] = np.median(all_smape_rolling_2, axis=0)\n",
    "\n",
    "            average_l2[(equation_name,context_length)] = np.mean(all_l2)\n",
    "            median_l2[(equation_name,context_length)] = np.median(all_l2)\n",
    "\n",
    "            average_cdim[(equation_name,context_length)] = np.mean(all_cdim, axis=0)\n",
    "            median_cdim[(equation_name,context_length)] = np.median(all_cdim, axis=0)\n",
    "            average_kl[(equation_name,context_length)] = np.nanmean(all_kl_dist)\n",
    "            median_kl[(equation_name,context_length)] = np.nanmedian(all_kl_dist)\n",
    "\n",
    "            average_mse[(equation_name,context_length)] = np.mean(all_mse_rolling, axis=0)\n",
    "            median_mse[(equation_name,context_length)] = np.median(all_mse_rolling, axis=0)\n",
    "            average_mae[(equation_name,context_length)] = np.mean(all_mae_rolling, axis=0)\n",
    "            median_mae[(equation_name,context_length)] = np.median(all_mae_rolling, axis=0)\n",
    "            \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Skipping {equation_name}\", flush=True)\n",
    "        continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./parrot_statistics_normalized/D={D}_average_vpt.npy', average_vpt)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_vpt.npy', median_vpt) \n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_smape.npy', average_smape)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_smape.npy', median_smape)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_vpt_2.npy', average_vpt_2)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_vpt_2.npy', median_vpt_2) \n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_smape_2.npy', average_smape_2)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_smape_2.npy', median_smape_2)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_cdim.npy', average_cdim)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_cdim.npy', median_cdim)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_kl.npy', average_kl)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_kl.npy', median_kl)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_mse.npy', average_mse)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_mse.npy', median_mse)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_mae.npy', average_mae)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_mae.npy', median_mae)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_average_l2.npy', average_l2)\n",
    "np.save(f'./parrot_statistics_normalized/D={D}_median_l2.npy', median_l2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
